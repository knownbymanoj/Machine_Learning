{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/knownbymanoj/Machine_Learning/blob/main/ScikitLearn_and_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoYYpizuMiwJ"
      },
      "source": [
        "#Lab 2: Introduction to ScikiLearn and Classification Tasks\n",
        "\n",
        "During this Lab, we aim to achieve the following:\n",
        "\n",
        "\n",
        "*   Familiarize with <a href=\"https://scikit-learn.org/stable/\"> scikit-learn </a>, an essential python library in data science;\n",
        "*   learn how to approach a classification task with scikit-learn.\n",
        "\n",
        "In this notebook, we learn to use Scikit-Learn with a practical example and then, in the second part, we will test our knowledge by doing some exercises.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YssOU-ZhNczi"
      },
      "source": [
        "# Part 1: A Classification Example With Scikit-Learn\n",
        "\n",
        "We start our lab by reimplementing the *homemade perceptron* using  scikit-learn. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02sO8JSRMXXZ"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhTmIt8NN0ur"
      },
      "source": [
        "X_toy, y_toy = datasets.make_blobs(n_samples=150,n_features=2,\n",
        "                           centers=2,cluster_std=1.05,\n",
        "                           random_state=2)\n",
        "y_toy[y_toy==0]=-1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q2QIo9EPe7h"
      },
      "source": [
        "We can now define our classifier: a perceptron <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html\"> [link] </a>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYjwdbMaPvsX"
      },
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "# we define two peceptrons: one with and one without intercept estimation (our theta_0)\n",
        "clf1 = Perceptron(fit_intercept = False)\n",
        "clf2 = Perceptron(fit_intercept = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N6MC_b2QJ_K"
      },
      "source": [
        "Sklearn defines standard functions for models, like *fit* and *predict*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4qlKvhrQQnV"
      },
      "source": [
        "#train phase\n",
        "clf1.fit(X_toy, y_toy)\n",
        "clf2.fit(X_toy, y_toy)\n",
        "\n",
        "#estimation (y_hat)\n",
        "y_pred_clf1 = clf1.predict(X_toy)\n",
        "y_pred_clf2 = clf2.predict(X_toy)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7v6JjDVQnLH"
      },
      "source": [
        "How to evaluate our models' performance? <br>\n",
        "Scikit-learn offers a broad set of evaluation functions already implemented <a href = \"https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\">[link]</a>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3wse3MyQmp7",
        "outputId": "dab1156d-f1bb-40aa-ec83-9bf71d8ceab6"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(f\"CLF1 -- no intercept.\\tACC: {accuracy_score(y_toy, y_pred_clf1)}\")\n",
        "print(f\"CLF2 -- with intercept.\\tACC: {accuracy_score(y_toy, y_pred_clf2)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLF1 -- no intercept.\tACC: 0.7733333333333333\n",
            "CLF2 -- with intercept.\tACC: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpjsDkvVN_vD"
      },
      "source": [
        "## Model Selection\n",
        "When defining or training a model, we have the so called *hyperparameters*, i.e., different settings to configure for our training strategy.  <br>\n",
        "The question is: *how can we decide the best configuration setting for the task?* <br>\n",
        "The answer is the usage of *training* and *validation* partitions. <br>\n",
        "We can use sklearn to do that: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u53o2430OsJG",
        "outputId": "6c602173-804a-4288-d0ff-ff2498ccb8b4"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_toy, y_toy, \n",
        "                                                  train_size = 0.8, random_state = 123)\n",
        "\n",
        "print(f\"Original size = {X_toy.shape[0]}\\tTrain size = {X_train.shape[0]}\\tVal size = {X_val.shape[0]}\")  # alternative way to use the print when there are  \n",
        "                                                                                                          # variables and text to print together"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original size = 150\tTrain size = 120\tVal size = 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK6pa1LuRlgR"
      },
      "source": [
        "# Part 2: Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfmw2jjz4g_M"
      },
      "source": [
        "### Ex 2.1 Logistic Regression\n",
        "\n",
        "Use Scikit-Learn to train a <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\">Logistic Regression</a> classifier with default parameters over the previously defined dataset (Lab introduction). <br>\n",
        "Compure the accuracy in both training and validation sets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8uueqGGSBJd"
      },
      "source": [
        "#\n",
        "# Ex 2.1: complete here\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4avSSrcSFK0",
        "outputId": "67bef86d-fdde-40c2-9207-62cc34384f93"
      },
      "source": [
        "#--------SOLUTIONS-------------\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf_lr = LogisticRegression()\n",
        "clf_lr.fit(X_train, y_train)\n",
        "\n",
        "#estimation (y_hat)\n",
        "y_train_pred_lr = clf_lr.predict(X_train)\n",
        "y_val_pred_lr = clf_lr.predict(X_val)\n",
        "\n",
        "print(f\"Logistic Regression.\\tTrain ACC: {accuracy_score(y_train, y_train_pred_lr)}\")\n",
        "print(f\"Logistic Regression.\\tVal ACC: {accuracy_score(y_val, y_val_pred_lr)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression.\tTrain ACC: 0.8714285714285714\n",
            "Logistic Regression.\tVal ACC: 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwnRlnJITqat"
      },
      "source": [
        "### Ex 2.2 Logistic Regression (2)\n",
        "\n",
        "We ask you again to work on a classification task. <br>\n",
        "This time, the classification is more challenging.\n",
        "The dataset is called *sonar*. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPaGZnJTTzYH"
      },
      "source": [
        "import pandas as pd\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/sonar.csv'\n",
        "ds = pd.read_csv(url, header = None)\n",
        "\n",
        "# split into input and output elements\n",
        "data = ds.values\n",
        "X_sonar, y_sonar = data[:, :-1], data[:, -1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqKEmbmmUbRx"
      },
      "source": [
        "**EX 2.2.1** Print the shapes of our arrays $X$ and $y$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffj2tb_WU1H8",
        "outputId": "3a21e88c-60fb-47f3-8728-c2b3dbb7fdb4"
      },
      "source": [
        "#--------SOLUTIONS-------------\n",
        "print(X_sonar.shape, y_sonar.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(208, 60) (208,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_8KkpEiVDH2"
      },
      "source": [
        "It's time to partition our dataset. <br>\n",
        "We ask you to create three partitions:\n",
        "\n",
        "\n",
        "*   *train set* : a set of samples used to train a model.\n",
        "*   *val set*: a set of samples used to decide the best model.\n",
        "*   *test set*: a set of samples used to see our best model performance. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3Cl4DNbISPc"
      },
      "source": [
        "We now first split samples that we can use in our training (train and val), from samples that we cannot touch (test). <br>\n",
        "**EX 2.2.2** Create a split between train_val and test, by maintaining the 25% of samples in the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piMMVXyBVPXy"
      },
      "source": [
        "# X_train_val, X_test, y_train_val, y_test = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMagQlKcVRIG"
      },
      "source": [
        "#--------SOLUTIONS-------------\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X_sonar, y_sonar, \n",
        "                                                  train_size = 0.75, random_state = 123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puQHU1EiI5lW"
      },
      "source": [
        "**EX 2.2.3** From the train_val variables, split train and validation sets. Maintain the 10% of samples in the validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK3dVG5VJJcW"
      },
      "source": [
        "# X_train, X_val, y_train, y_val = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "js9KFcG4JQ9O"
      },
      "source": [
        "#--------SOLUTIONS-------------\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, \n",
        "                                                  train_size = 0.9, random_state = 123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5xWObuEVbOP"
      },
      "source": [
        "Sklearn uses a different name for the hyperparameter $\\lambda$, can you recognise it in the documentation from its description? What is the default value for the parameter? What is its relationship with $\\lambda$?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdfZymBTnmls"
      },
      "source": [
        "\n",
        "Solution: $\\lambda=\\frac{1}{C}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHh4F6EonDL4"
      },
      "source": [
        "Sklearn uses a different name for the hyperparameter $\\lambda$, can you recognise it in the documentation from its description? What is the default value for the parameter? What is its relationship with $\\lambda$?\n",
        "\n",
        "**EX 2.2.4** Train and evaluate (using accuracy) a logistic regression with the default value for the hyperparameter. Do the evaluation **only** on the training and evaluation partitions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ps2GLaxaVjGy",
        "outputId": "1cb3bc48-133d-4012-d35d-e72a34b0c45b"
      },
      "source": [
        "#--------SOLUTION-------------\n",
        "clf_lr = LogisticRegression()\n",
        "clf_lr.fit(X_train, y_train)\n",
        "\n",
        "#estimation (y_hat)\n",
        "y_train_pred_lr = clf_lr.predict(X_train)\n",
        "y_val_pred_lr = clf_lr.predict(X_val)\n",
        "\n",
        "print(f\"Logistic Regression.\\tTrain ACC: {accuracy_score(y_train, y_train_pred_lr)}\")\n",
        "print(f\"Logistic Regression.\\tVal ACC: {accuracy_score(y_val, y_val_pred_lr)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression.\tTrain ACC: 0.8714285714285714\n",
            "Logistic Regression.\tVal ACC: 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRwSJs1gVsPk"
      },
      "source": [
        "This time we do not reach the 100% of accuracy in both training and validation set. <br>\n",
        "A good strategy is to apply a grid-search, i.e., find a sub-optimal hyperparameters. <br>\n",
        "We now ask you to manually implement a grid-search for *C*, an hyperparameter of the model. <br>\n",
        "See the documentation <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\"> [link] </a>. <br>\n",
        "**EX 2.2.5**  We ask you to find the best *C* among the following: $C = [0.001, 0.01, 0.1, 1., 10]$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mloaRMsPWg0I"
      },
      "source": [
        "C = [0.001, 0.01, 0.1, 1., 10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ENLqyKpWneR",
        "outputId": "2f760130-07a6-4bf6-fcf4-444064639537"
      },
      "source": [
        "#--------SOLUTION-------------\n",
        "C = [0.001, 0.01, 0.1, 1., 10, 100]\n",
        "for c in C:\n",
        "    clf_lr = LogisticRegression(C = c, max_iter = 200)\n",
        "    clf_lr.fit(X_train, y_train)\n",
        "\n",
        "    #estimation (y_hat)\n",
        "    y_train_pred_lr = clf_lr.predict(X_train)\n",
        "    y_val_pred_lr = clf_lr.predict(X_val)\n",
        "    tr_acc = accuracy_score(y_train, y_train_pred_lr)\n",
        "    val_acc= accuracy_score(y_val, y_val_pred_lr)\n",
        "\n",
        "    print(f\"LR. C= {c}.\\tTrain ACC: {tr_acc}\\tVal Acc: {val_acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR. C= 0.001.\tTrain ACC: 0.55\tVal Acc: 0.3125\n",
            "LR. C= 0.01.\tTrain ACC: 0.5857142857142857\tVal Acc: 0.3125\n",
            "LR. C= 0.1.\tTrain ACC: 0.75\tVal Acc: 0.5\n",
            "LR. C= 1.0.\tTrain ACC: 0.8714285714285714\tVal Acc: 0.75\n",
            "LR. C= 10.\tTrain ACC: 0.8785714285714286\tVal Acc: 0.75\n",
            "LR. C= 100.\tTrain ACC: 0.9357142857142857\tVal Acc: 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxp8zprVXIdL"
      },
      "source": [
        "The default parameter seems to work fine. <br>\n",
        "We might want to extend the search in a smaller range: $C=[0.1, 0.5, 1, 5, 10, 15, 20] $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xckj-5IXZxE"
      },
      "source": [
        "C=[0.1, 0.5, 1, 5, 10, 15, 20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7AniqXhXgwA",
        "outputId": "93f67c76-27e6-4f72-d873-c5f2b8c24a20"
      },
      "source": [
        "#--------SOLUTION-------------\n",
        "for c in C:\n",
        "    clf_lr = LogisticRegression(C = c)\n",
        "    clf_lr.fit(X_train, y_train)\n",
        "\n",
        "    #estimation (y_hat)\n",
        "    y_train_pred_lr = clf_lr.predict(X_train)\n",
        "    y_val_pred_lr = clf_lr.predict(X_val)\n",
        "    tr_acc = accuracy_score(y_train, y_train_pred_lr)\n",
        "    val_acc= accuracy_score(y_val, y_val_pred_lr)\n",
        "\n",
        "    print(f\"LR. C= {c}.\\tTrain ACC: {tr_acc}\\tVal Acc: {val_acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR. C= 0.1.\tTrain ACC: 0.75\tVal Acc: 0.5\n",
            "LR. C= 0.5.\tTrain ACC: 0.8428571428571429\tVal Acc: 0.6875\n",
            "LR. C= 1.\tTrain ACC: 0.8714285714285714\tVal Acc: 0.75\n",
            "LR. C= 5.\tTrain ACC: 0.8714285714285714\tVal Acc: 0.75\n",
            "LR. C= 10.\tTrain ACC: 0.8785714285714286\tVal Acc: 0.75\n",
            "LR. C= 15.\tTrain ACC: 0.8928571428571429\tVal Acc: 0.75\n",
            "LR. C= 20.\tTrain ACC: 0.9\tVal Acc: 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfbEDDN2Xni3"
      },
      "source": [
        "There is no much difference, but we find sub-optimal values with $C= [1, 5, 10, 20$]. <br>\n",
        "Note that while the training performance vary, the validation set is the same between these four values.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgfoeKfaYBvV"
      },
      "source": [
        "In the official documentation, we find several hyperparameters we can tune. <br>\n",
        "For example, you might want to see what happen when we do not fit the intercept. To do so, we should try both combinations (i.e., true and false) for the parameters, but by combining all the possible C we found up to now. <br>\n",
        "Since we use 6 possible values for $C$ and 2 for $fit intercept$, the total number of trials are $6 * 2 = 12$. <br>\n",
        "Python-related speaking, this is translated into an inner loop, i.e., a loop inside a loop:\n",
        "\n",
        "    for c in [0.1, 0.5, 1, 5, 10, 15, 20]:\n",
        "        for fi in [True, False]:\n",
        "            #here we train and test our model\n",
        "\n",
        "If we want to find the sub-optimal amond three hyper-parameters, we must add another innner loop. If we have 10 hyper-parameters, we'll have 10 inner loops! <br>\n",
        "For now, we can do it manually. Find the sub-optimal values using the validation performance. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WfZkiv8dKnM"
      },
      "source": [
        "C=[0.1, 0.5, 1, 5, 10, 15, 20]\n",
        "FI = [True, False]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzdl2OAKdTgD",
        "outputId": "61ad4f5b-f3a6-4688-a0bd-ec7f19c68be3"
      },
      "source": [
        "#--------SOLUTION-------------\n",
        "best_C = None\n",
        "best_fi = None\n",
        "best_train_acc = 0.\n",
        "best_val_acc = 0.\n",
        "\n",
        "for c in C:\n",
        "    for fi in FI:\n",
        "        clf_lr = LogisticRegression(C = c, fit_intercept= fi)\n",
        "        clf_lr.fit(X_train, y_train)\n",
        "\n",
        "        #estimation (y_hat)\n",
        "        y_train_pred_lr = clf_lr.predict(X_train)\n",
        "        y_val_pred_lr = clf_lr.predict(X_val)\n",
        "\n",
        "        tr_acc = accuracy_score(y_train, y_train_pred_lr)\n",
        "        val_acc= accuracy_score(y_val, y_val_pred_lr)\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_C = c\n",
        "            best_fi = fi\n",
        "            best_train_acc = tr_acc\n",
        "            best_val_acc = val_acc\n",
        "\n",
        "print(f\"Found the best model with C:{best_C}\\tFit Intercept:{best_fi}\")\n",
        "print(f\"Best training acc:{best_train_acc}\\tBest val acc:{best_val_acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found the best model with C:1\tFit Intercept:True\n",
            "Best training acc:0.8714285714285714\tBest val acc:0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hfh8A6gLbWW"
      },
      "source": [
        "We don't get much improvement, since we obtain similar a similar score compared to the \"defaul\" Logistic Regression. Don't worry about it, it just a toy-sh dataset. During the next weeks we are going to see more realistic tasks where a proper parameter selection can make the difference. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NcUoUqSlGmV"
      },
      "source": [
        "# Ex 2.3 Grid Search Cross-Validation\n",
        "\n",
        "In the previous exercise, we implemented a grid search manually. <br>\n",
        "The more hyper-parameters, the harder to implement. <br>\n",
        "Scikit-learn eases our pain, and it offers a grid-search cross-validation function that does everything for us! <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\"> [link]</a>.<br> \n",
        "We now see together an example of grid-search implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bwxkeSVmq0z"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV #import the library"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DjUPAiGmx0h"
      },
      "source": [
        "The first thing to do is to define a dictionary containing the hyper-parameters with the range of values we want to search on. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyvBfn1omwSS"
      },
      "source": [
        "param_grid_test = {\n",
        "    'C': [0.1, 0.5, 1, 5, 10, 15, 20],\n",
        "    'fit_intercept': [True, False]\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw21-uMJncqa"
      },
      "source": [
        "Then, we create the grid-search object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RghpaQtnhzw"
      },
      "source": [
        "#target classifier\n",
        "lr = LogisticRegression()\n",
        "\n",
        "#grid-search object\n",
        "clf = GridSearchCV(estimator= lr, param_grid=param_grid_test, \n",
        "                   cv = 5, scoring = \"accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5Ijn5msnw4o"
      },
      "source": [
        "Finally, we can find the best model. <br>\n",
        "Note that the tool already refit the best fund model in the entire dataset (i.e., train and validation). <br> \n",
        "This is a default parameter of the grid-search CV (see the documentation).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SrEmPuynwX4",
        "outputId": "e66643ff-aa23-4a0a-a2b1-f6c7447617d9"
      },
      "source": [
        "#fit the model\n",
        "clf.fit(X_toy, y_toy) #we do not use the train - validation split strategy since it is included in the CV procedure\n",
        "\n",
        "#see the best parameters and performance\n",
        "print(clf.best_params_)\n",
        "print(clf.best_score_)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 0.1, 'fit_intercept': True}\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsDxM9Jopk2V"
      },
      "source": [
        "Now let's implement a grid-search CV with 10 fold for the *sonar* dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKuEGYgmp1iO",
        "outputId": "14c7469b-d051-43c6-ec47-df27aaade27b"
      },
      "source": [
        "#--------SOLUTION-------------\n",
        "#define the parameters grid\n",
        "param_grid = {\n",
        "    'C': [0.1, 0.5, 1, 5, 10, 15, 20],\n",
        "    'fit_intercept': [True, False]\n",
        "}\n",
        "\n",
        "#target classifier\n",
        "lr = LogisticRegression(max_iter= 200)\n",
        "\n",
        "#grid-search object\n",
        "clf = GridSearchCV(estimator= lr, param_grid=param_grid, cv = 10, scoring = \"accuracy\")\n",
        "\n",
        "#fit the model\n",
        "clf.fit(X_train_val, y_train_val) #we do not use the train - validation split strategy since it is included in the CV procedure\n",
        "\n",
        "#see the best parameters and performance\n",
        "print(clf.best_params_)\n",
        "print(clf.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 15, 'fit_intercept': False}\n",
            "0.7883333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Uo5APXyomcf"
      },
      "source": [
        "The grid-search cv returns a different Logistic Regression model, with $C=15$ and $fit\\;intercept=False$.  <br>\n",
        "\n",
        "It's time to see this best model on the test set. Use the accuracy as evaluation metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNA1yHhIM7yu",
        "outputId": "310a45df-310c-41e2-875c-1d963c5bd0c1"
      },
      "source": [
        "#--------SOLUTION-------------\n",
        "y_test_pred = clf.predict(X_test)\n",
        "print(accuracy_score(y_test, y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7884615384615384\n"
          ]
        }
      ]
    }
  ]
}